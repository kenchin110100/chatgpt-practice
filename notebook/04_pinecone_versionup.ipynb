{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e73db0a5",
   "metadata": {},
   "source": [
    "# PINECONEを用いたvectorサーチのデモ\n",
    "\n",
    "llama_indexのバージョンが上がったので、それに伴いコードを修正\n",
    "\n",
    "2. 技術ブログの登録\n",
    "\n",
    "- https://gpt-index.readthedocs.io/en/stable/how_to/integrations/vector_stores.html\n",
    "\n",
    "\n",
    "# 方針\n",
    "\n",
    "- LangChain.Agentを利用せずに、LLamaIndex単体で実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96ecb529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.vector_stores import PineconeVectorStore\n",
    "from llama_index import SimpleWebPageReader, LLMPredictor, ServiceContext, OpenAIEmbedding, GPTVectorStoreIndex, StorageContext\n",
    "from llama_index.prompts.prompts import QuestionAnswerPrompt, RefinePrompt\n",
    "import pinecone\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "INDEX_NAME = \"chatgpt-search-index\"\n",
    "\n",
    "PREDICTOR_MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "\n",
    "INITIAL_URLS = [\n",
    "    \"https://dev.classmethod.jp/articles/lang-chain-agent-customized-by-llama-index-tool/\",\n",
    "    \"https://yukoishizaki.hatenablog.com/entry/2020/05/24/145155\",\n",
    "    \"https://runble1.com/gcp-terraform-cloud-run/\"\n",
    "]\n",
    "ADDITIONAL_URL = \"https://zenn.dev/tfutada/articles/acf8adbb2ba5be\"\n",
    "\n",
    "# カスタムテンプレートの作成\n",
    "CUSTOM_TEXT_QA_PROMPT_TMPL = (\n",
    "    \"コンテキストは以下です. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"コンテキストが与えられた場合, \"\n",
    "    \"質問に回答してください: {query_str}\\n\"\n",
    ")\n",
    "CUSTOM_TEXT_QA_PROMPT = QuestionAnswerPrompt(CUSTOM_TEXT_QA_PROMPT_TMPL)\n",
    "\n",
    "CUSTOM_REFINE_PROMPT_TMPL = (\n",
    "    \"元の質問: {query_str}\\n\"\n",
    "    \"オリジナルの回答: {existing_answer}\\n\"\n",
    "    \"以下のコンテキストを使って、オリジナルの回答を推敲することができます.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{context_msg}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"コンテキストを元に、オリジナルの回答を、より元の質問に沿ったものに推敲してください. \"\n",
    "    \"もしコンテキストが有用なものでなければ、オリジナルの回答を返却してください\"\n",
    ")\n",
    "CUSTOM_REFINE_PROMPT = RefinePrompt(CUSTOM_REFINE_PROMPT_TMPL)\n",
    "\n",
    "# 環境変数の読み込み\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "690c82ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# デバッグする際に実行\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190d8bc1",
   "metadata": {},
   "source": [
    "# 既存DBへの接続 & 検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bc98b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clientの作成\n",
    "pinecone.init(api_key=os.environ[\"PINECONE_API_KEY\"], environment=os.environ[\"PINECONE_ENVIRONMENT\"])\n",
    "pinecone_index = pinecone.Index(INDEX_NAME)\n",
    "\n",
    "vector_store = PineconeVectorStore(\n",
    "    pinecone_index=pinecone_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e889988e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 48}},\n",
       " 'total_vector_count': 48}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "532e877a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:llama_index.llm_predictor.base:Unknown max input size for gpt-3.5-turbo, using defaults.\n",
      "Unknown max input size for gpt-3.5-turbo, using defaults.\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 0 tokens\n",
      "> [build_index_from_nodes] Total embedding token usage: 0 tokens\n"
     ]
    }
   ],
   "source": [
    "# indexのセットアップ\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store = vector_store\n",
    ")\n",
    "\n",
    "llm_predictor = LLMPredictor(\n",
    "    llm=ChatOpenAI(\n",
    "        temperature=0, model_name=PREDICTOR_MODEL_NAME, openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "embed_model = OpenAIEmbedding(\n",
    "    model=EMBEDDING_MODEL_NAME\n",
    ")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm_predictor=llm_predictor,\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "index = GPTVectorStoreIndex.from_documents(\n",
    "    documents=[], service_context=service_context, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "488350eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 48}},\n",
       " 'total_vector_count': 48}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6a5438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    text_qa_template=CUSTOM_TEXT_QA_PROMPT,\n",
    "    refine_template=CUSTOM_REFINE_PROMPT,\n",
    "    similarity_top_k=3\n",
    ")\n",
    "\n",
    "search_query = \"calibrationってどんな技術だっけ？\"\n",
    "\n",
    "response = query_engine.query(\n",
    "    search_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d095e1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: Calibrationは、モデルの確率予測の信頼性を高めるための技術で、モデルの出力値を各クラスに属する確率に近づけることを指します。具体的には、Sigmoid / Platt ScaleやIsotonic Regressionなどの手法を使って、モデルの出力値を正解ラベルのクラス分布に近づけます。最近のニューラルネットワークは自信過剰で、Calibrationが必要な場合もあります。また、MMMなどの統計分析だけでは過学習している可能性があるため、交差検証を行うことが重要です。A/Bテストを行うことで、交差検証を補完し、モデルの信頼性を高めることができます。\n",
      "参照url1: https://tjo.hatenablog.com/entry/2023/04/26/191100\n",
      "参照url2: https://yukoishizaki.hatenablog.com/entry/2020/05/24/145155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikegamikenshin/Documents/study/chatgpt-practice/.venv/lib/python3.9/site-packages/llama_index/data_structs/node.py:181: UserWarning: .extra_info is deprecated, use .node.extra_info instead\n",
      "  warnings.warn(\".extra_info is deprecated, use .node.extra_info instead\")\n"
     ]
    }
   ],
   "source": [
    "print(f\"response: {response.response}\")\n",
    "\n",
    "reffer_urls = set([source_node.extra_info[\"url\"] for source_node in response.source_nodes])\n",
    "for i, url in enumerate(reffer_urls):\n",
    "    print(f\"参照url{i+1}: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80572c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 48}},\n",
       " 'total_vector_count': 48}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1226d03b",
   "metadata": {},
   "source": [
    "# データのインサート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb5f5a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 48}},\n",
       " 'total_vector_count': 48}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02921838",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"DIDについて教えて\"\n",
    "\n",
    "response = query_engine.query(\n",
    "    search_query\n",
    ")\n",
    "\n",
    "print(f\"response: {response.response}\")\n",
    "\n",
    "reffer_urls = set([source_node.extra_info[\"url\"] for source_node in response.source_nodes])\n",
    "for i, url in enumerate(reffer_urls):\n",
    "    print(f\"参照url{i+1}: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5422f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# webページからdocumentクラスを作成\n",
    "samples_urls = [\"https://zenn.dev/s1ok69oo/articles/e786bd6ee2d1f0\"]\n",
    "\n",
    "\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(samples_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69d4c4d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extra_infoにurlを追加\n",
    "for document, url in zip(documents, samples_urls):\n",
    "    document.extra_info = {\"url\": url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc0e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in documents:\n",
    "        index.insert(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c251efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 62}},\n",
       " 'total_vector_count': 62}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3735d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"DIDについて教えて\"\n",
    "\n",
    "response = query_engine.query(\n",
    "    search_query\n",
    ")\n",
    "\n",
    "print(f\"response: {response.response}\")\n",
    "\n",
    "reffer_urls = set([source_node.extra_info[\"url\"] for source_node in response.source_nodes])\n",
    "for i, url in enumerate(reffer_urls):\n",
    "    print(f\"参照url{i+1}: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ea08f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7012dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8dd154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75090193",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_response = pinecone_index.query(\n",
    "    top_k=10,\n",
    "    include_metadata=True,\n",
    "    # dummyのベクトル\n",
    "    vector=[0.1] * 1536,\n",
    "    filter={\n",
    "         \"extra_info_url\": {\"$in\": [\"https://zenn.dev/s1ok69oo/articles/e786bd6ee2d1f0\"]}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "530938e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_response[\"matches\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176638f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2af71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3466fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "595663eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6361606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
