{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b57a98b",
   "metadata": {},
   "source": [
    "LangChainの調査"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a3234b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b44d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model_name: str = \"text-davinci-003\"\n",
    "    \"\"\"Model name to use.\"\"\"\n",
    "    temperature: float = 0.7\n",
    "    \"\"\"What sampling temperature to use.\"\"\"\n",
    "    max_tokens: int = 256\n",
    "    \"\"\"The maximum number of tokens to generate in the completion.\n",
    "    -1 returns as many tokens as possible given the prompt and\n",
    "    the models maximal context size.\"\"\"\n",
    "    top_p: float = 1\n",
    "    \"\"\"Total probability mass of tokens to consider at each step.\"\"\"\n",
    "    frequency_penalty: float = 0\n",
    "    \"\"\"Penalizes repeated tokens according to frequency.\"\"\"\n",
    "    presence_penalty: float = 0\n",
    "    \"\"\"Penalizes repeated tokens.\"\"\"\n",
    "    n: int = 1\n",
    "    \"\"\"How many completions to generate for each prompt.\"\"\"\n",
    "    best_of: int = 1\n",
    "    \"\"\"Generates best_of completions server-side and returns the \"best\".\"\"\"\n",
    "    model_kwargs: Dict[str, Any] = Field(default_factory=dict)\n",
    "    \"\"\"Holds any model parameters valid for `create` call not explicitly specified.\"\"\"\n",
    "    openai_api_key: Optional[str] = None\n",
    "    openai_api_base: Optional[str] = None\n",
    "    openai_organization: Optional[str] = None\n",
    "    batch_size: int = 20\n",
    "    \"\"\"Batch size to use when passing multiple documents to generate.\"\"\"\n",
    "    request_timeout: Optional[Union[float, Tuple[float, float]]] = None\n",
    "    \"\"\"Timeout for requests to OpenAI completion API. Default is 600 seconds.\"\"\"\n",
    "    logit_bias: Optional[Dict[str, float]] = Field(default_factory=dict)\n",
    "    \"\"\"Adjust the probability of specific tokens being generated.\"\"\"\n",
    "    max_retries: int = 6\n",
    "    \"\"\"Maximum number of retries to make when generating.\"\"\"\n",
    "    streaming: bool = False\n",
    "    \"\"\"Whether to stream the results or not.\"\"\"\n",
    "    allowed_special: Union[Literal[\"all\"], AbstractSet[str]] = set()\n",
    "    \"\"\"Set of special tokens that are allowed。\"\"\"\n",
    "    disallowed_special: Union[Literal[\"all\"], Collection[str]] = \"all\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dac468f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'私はAIであるため、味わうことができないため、季節に合わせた料理のおすすめは提供できませんが、一般的に秋は栗やかぼちゃ、秋刀魚などがおすすめです。冬は鍋料理や煮込み料理、餅などが人気です。春は新鮮な野菜を使ったサラダや、桜餅などがおすすめです。夏は冷たい素麺や冷やし中華、かき氷などが人気です。'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llms: OpenAIのラッパー\n",
    "# OpenAIChatとの違い\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.7,\n",
    "    n=1,\n",
    ")\n",
    "\n",
    "text = \"今の季節におすすめの料理は？\"\n",
    "\n",
    "llm(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c438030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "・もつ（豚の内臓）\n",
      "    ・白菜\n",
      "    ・にら\n",
      "    ・にんにく\n",
      "    ・生姜\n",
      "    ・しょうゆ\n",
      "    ・酒\n",
      "    ・みりん\n",
      "    ・水\n",
      "    ・豆腐\n",
      "    ・長ネギ\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"\"\"\n",
    "    Q: カレーの材料は？\n",
    "    A: 材料:\n",
    "    ・ジャガイモ\n",
    "    ・にんじん\n",
    "    ・牛肉\n",
    "    ・カレー粉\n",
    "    \n",
    "    Q: {product}の材料は？\n",
    "    A: 材料\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "print(chain.run(\"もつ鍋\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70f852ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日本語に対応できてないし、安定性がイマイチ\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    n=1,\n",
    ")\n",
    "tools = load_tools([\"serpapi\"], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    # https://book.st-hakky.com/docs/example-of-agents-of-langchain/\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "text1 = \"大谷選手の最近の成績は？\"\n",
    "text2 = \"大谷選手の最近の打率は？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c798c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI'm not sure what 大谷選手 means, I should look it up.\n",
      "Action: Search\n",
      "Action Input: \"大谷選手 最近の成績\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m大谷翔平の最新打撃成績、速報、成績などを掲載 - 日刊スポーツ新聞社のニュースサイト、ニッカンスポーツ・コム（nikkansports.com）。\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI found the information I needed, now I just need to translate it.\n",
      "Action: Search\n",
      "Action Input: \"translate nikkansports.com\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNikkan Sports is the first-launched Japanese daily sports newspaper founded in 1946. ... This article may be expanded with text translated from the corresponding ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThat wasn't helpful, I should try a different translation tool.\n",
      "Action: Search\n",
      "Action Input: \"translate nikkansports.com with google translate\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mGoogle's service, offered free of charge, instantly translates words, phrases, and web pages between English and over 100 other languages.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mGreat, now I can finally translate the article and find out 大谷選手's recent performance.\n",
      "Action: Search\n",
      "Action Input: \"大谷翔平 最新打撃成績\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m大谷翔平の最新打撃成績、速報、成績などを掲載 - 日刊スポーツ新聞社のニュースサイト、ニッカンスポーツ・コム（nikkansports.com）。\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: According to nikkansports.com, 大谷翔平's recent batting performance is posted on their website.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"According to nikkansports.com, 大谷翔平's recent batting performance is posted on their website.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ecaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# エラーが発生\n",
    "agent.run(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb228d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: おはよう！\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "おはようございます！朝ですね。今日は何をしますか？(Good morning! It's morning. What are you going to do today?)\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "llm = OpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    n=1,\n",
    ")\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "\n",
    "output = conversation.predict(input=\"おはよう！\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "216c7dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: おはよう！\n",
      "AI: おはようございます！朝ですね。今日は何をしますか？(Good morning! It's morning. What are you going to do today?)\n",
      "Human: おすすめはありますか？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "はい、たとえば、天気が良ければ公園に行くことをお勧めします。また、新しいレストランを試すこともできます。あなたの好みに合わせて、いくつかのオプションを提供することができます。(Yes, for example, if the weather is nice, I recommend going to the park. You could also try a new restaurant. I can provide several options based on your preferences.)\n"
     ]
    }
   ],
   "source": [
    "output = conversation.predict(input=\"おすすめはありますか？\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdd5942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate, \n",
    "    MessagesPlaceholder, \n",
    "    SystemMessagePromptTemplate, \n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "chat = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"語尾に「ごわす」という言葉をつけて喋ってください\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "])\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "conversation = ConversationChain(memory=memory, prompt=prompt, llm=chat, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd0c0a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: 語尾に「ごわす」という言葉をつけて喋ってください\n",
      "Human: おはよう！\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'おはようございます、ごわす！'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"おはよう！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c372565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: 語尾に「ごわす」という言葉をつけて喋ってください\n",
      "Human: おはよう！\n",
      "AI: おはようございます、ごわす！\n",
      "Human: 朝におすすめの音楽はありますか？\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'朝に聴くと良いと思われる音楽は、ジャンルによって異なりますが、私がおすすめするのは、ジャズやクラシック、または穏やかなポップスなどです。例えば、ビル・エヴァンスの「Sunday at the Village Vanguard」や、ショパンの「ノクターン第2番」、ジョン・レジェンドの「All of Me」などがあります。ご参考までに、ごわす。'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"朝におすすめの音楽はありますか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92b022dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: 語尾に「ごわす」という言葉をつけて喋ってください\n",
      "Human: おはよう！\n",
      "AI: おはようございます、ごわす！\n",
      "Human: 朝におすすめの音楽はありますか？\n",
      "AI: 朝に聴くと良いと思われる音楽は、ジャンルによって異なりますが、私がおすすめするのは、ジャズやクラシック、または穏やかなポップスなどです。例えば、ビル・エヴァンスの「Sunday at the Village Vanguard」や、ショパンの「ノクターン第2番」、ジョン・レジェンドの「All of Me」などがあります。ご参考までに、ごわす。\n",
      "Human: 他におすすめはありますか？\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'はい、朝に聴くと良いと思われる音楽として、以下の曲もおすすめです。\\n\\n- ボサノバ：アストラッド・ジルベルトの「The Girl from Ipanema」\\n- クラシック：モーツァルトの「アイネ・クライネ・ナハトムジーク」\\n- ジャズ：チック・コリアの「Spain」\\n- ポップス：ビートルズの「Here Comes the Sun」\\n- インストゥルメンタル：石川さゆりの「津軽海峡・冬景色」のカバー\\n\\n朝の気分に合わせて、お好みの曲を選んで聴いてみてください。ごわす。'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"他におすすめはありますか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "867f2a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ドキュメントローダーをインポート\n",
    "from langchain.document_loaders import TextLoader\n",
    "# ドキュメントローダーの初期化\n",
    "loader = TextLoader(\"../data/人間失格.txt\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "874736cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# チャンクサイズの制限を下回るまで再帰的に分割するテキストスプリッターのインポート\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# テキストスプリッターの初期化\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=0)\n",
    "\n",
    "# テキストをチャンクに分割\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e73d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用するエンベッディングをインポート\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "# エンベッディングの初期化\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ab67fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "# vectorstore をインポート (ここでは Chroma を使用)\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# ベクターストアにドキュメントとエンベッディングを格納\n",
    "db = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29ea6266",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cdf4d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 質問と回答の取得に使用するチェーンをインポート\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# チェーンを作り、それを使って質問に答える\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a2325cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'文章には複数の主人公が登場していますが、それぞれの描写が異なります。最初の文章では、人間のからだに駄馬の首でもくっつけたような「死相」を持った男性の描写があります。第二の文章では、学生時代の写真が描写され、美貌の学生であるが、生きている人間の感じはしなかったという描写があります。最後の文章では、主人公の見た目については描写されていません。'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"主人公の見た目は？\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "82f04132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'主人公は父親の死による苦悩や、自分自身の存在意義についての苦悩を抱えていました。また、金銭的な問題にも悩まされていました。'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"主人公は何に苦しんでいた？\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57239370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "chat = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "qa_index_tool = Tool(\n",
    "    name=\"QA Index\"\n",
    "    , description=\"人間失格に関するindex\"\n",
    "    , func=qa.run\n",
    ")\n",
    "\n",
    "agent_executor = initialize_agent(\n",
    "    tools=[\n",
    "        qa_index_tool\n",
    "    ]\n",
    "    , llm=chat\n",
    "    , agent=\"conversational-react-description\"\n",
    "    , verbose=True\n",
    "    , memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "43c0b258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: 田山花袋の小説『人間失格』は、主人公の自堕落な生活と、その生活によって引き起こされる様々な問題を描いた作品です。主人公の孤独や絶望感、そして自己嫌悪が強く描かれており、読者に深い印象を与える作品となっています。また、田山花袋の独特な文体や、哲学的なテーマも注目されています。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'田山花袋の小説『人間失格』は、主人公の自堕落な生活と、その生活によって引き起こされる様々な問題を描いた作品です。主人公の孤独や絶望感、そして自己嫌悪が強く描かれており、読者に深い印象を与える作品となっています。また、田山花袋の独特な文体や、哲学的なテーマも注目されています。'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"どういう作品か教えて\"\n",
    "agent_executor.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d649416d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 動作が安定せずにエラーが発生する\n",
    "query = \"自堕落な生活ってどんなの？\"\n",
    "agent_executor.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43bbe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
