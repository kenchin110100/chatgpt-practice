{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e73db0a5",
   "metadata": {},
   "source": [
    "# QDRANTを用いたvectorサーチのデモ\n",
    "\n",
    "1. 技術ブログの検索\n",
    "  - 決まったフォーマットで出力\n",
    "  - URLも同時に返却\n",
    "  - 上位3つくらい\n",
    "\n",
    "2. 技術ブログの登録\n",
    "\n",
    "\n",
    "# 方針\n",
    "\n",
    "- LangChain.Agentを利用せずに、LLamaIndex単体で実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ecb529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from llama_index import SimpleWebPageReader, LLMPredictor, ServiceContext, GPTQdrantIndex, OpenAIEmbedding\n",
    "from llama_index.prompts.prompts import QuestionAnswerPrompt, RefinePrompt\n",
    "import qdrant_client\n",
    "from langchain import OpenAI\n",
    "\n",
    "COLLECTION_NAME = \"chatgpt_search_collection\"\n",
    "HOST = \"localhost\"\n",
    "PORT = 6333\n",
    "PREDICTOR_MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "INITIAL_URLS = [\n",
    "    \"https://dev.classmethod.jp/articles/lang-chain-agent-customized-by-llama-index-tool/\",\n",
    "    \"https://yukoishizaki.hatenablog.com/entry/2020/05/24/145155\",\n",
    "    \"https://runble1.com/gcp-terraform-cloud-run/\"\n",
    "]\n",
    "ADDITIONAL_URL = \"https://zenn.dev/tfutada/articles/acf8adbb2ba5be\"\n",
    "\n",
    "# カスタムテンプレートの作成\n",
    "CUSTOM_TEXT_QA_PROMPT_TMPL = (\n",
    "    \"コンテキストは以下です. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"コンテキストが与えられた場合, \"\n",
    "    \"質問に回答してください: {query_str}\\n\"\n",
    ")\n",
    "CUSTOM_TEXT_QA_PROMPT = QuestionAnswerPrompt(CUSTOM_TEXT_QA_PROMPT_TMPL)\n",
    "\n",
    "CUSTOM_REFINE_PROMPT_TMPL = (\n",
    "    \"元の質問: {query_str}\\n\"\n",
    "    \"オリジナルの回答: {existing_answer}\\n\"\n",
    "    \"以下のコンテキストを使って、オリジナルの回答を推敲することができます.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{context_msg}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"コンテキストを元に、オリジナルの回答を、より元の質問に沿ったものに推敲してください. \"\n",
    "    \"もしコンテキストが有用なものでなければ、オリジナルの回答を返却してください\"\n",
    ")\n",
    "CUSTOM_REFINE_PROMPT = RefinePrompt(CUSTOM_REFINE_PROMPT_TMPL)\n",
    "\n",
    "# 環境変数の読み込み\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690c82ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# デバッグする際に実行\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190d8bc1",
   "metadata": {},
   "source": [
    "# Indexの構築 & 検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bc98b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clientの作成\n",
    "client = qdrant_client.QdrantClient(\n",
    "    host=HOST,\n",
    "    https=False,\n",
    "    port=PORT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "532e877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.get_collection(collection_name=COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5422f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# webページからdocumentクラスを作成\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(INITIAL_URLS)\n",
    "\n",
    "# extra_infoにurlを追加\n",
    "for document, url in zip(documents, INITIAL_URLS):\n",
    "    document.extra_info = {\"url\": url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d4c4d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/chatgpt_search_collection \"HTTP/1.1 404 Not Found\"\n",
      "/Users/ikegamikenshin/Documents/study/chatgpt-practice/.venv/lib/python3.9/site-packages/langchain/llms/openai.py:158: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/ikegamikenshin/Documents/study/chatgpt-practice/.venv/lib/python3.9/site-packages/langchain/llms/openai.py:661: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/chatgpt_search_collection \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: DELETE http://localhost:6333/collections/chatgpt_search_collection \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/chatgpt_search_collection \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/chatgpt_search_collection/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 29977 tokens\n"
     ]
    }
   ],
   "source": [
    "# 既にDBにcollectionが存在する場合、その内容を利用\n",
    "try:\n",
    "    client.get_collection(collection_name=COLLECTION_NAME)\n",
    "    initial_documents = []\n",
    "except:\n",
    "    initial_documents = documents\n",
    "\n",
    "llm_predictor = LLMPredictor(\n",
    "    llm=OpenAI(\n",
    "        temperature=0, model_name=PREDICTOR_MODEL_NAME\n",
    "    )\n",
    ")\n",
    "\n",
    "embed_model = OpenAIEmbedding(\n",
    "    model=EMBEDDING_MODEL_NAME\n",
    ")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm_predictor=llm_predictor,\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "index = GPTQdrantIndex.from_documents(\n",
    "    client=client, collection_name=COLLECTION_NAME,\n",
    "    documents=initial_documents, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c251efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/chatgpt_search_collection/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 17150 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 21 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: Calibrationは、測定器やモデルの出力値を正確に調整するための技術です。機械学習においては、モデルの確率予測の信頼性を高めるために、Sigmoid/Platt ScaleやIsotonic Regressionなどの手法を用いて、モデルの出力値を各クラスに属する確率に近づけます。また、Calibration Curveを使って、確率予測の信頼度を可視化することもできます。Calibrationの評価指標としては、Brier Scoreがよく使われます。Calibrationは、不均衡データをUndersamplingした場合にも適用できます。ただし、LightGBMや最近のNNは自信過剰であるため、Calibrationが必要かどうかは、train, val, test のそれぞれの予測値/目的変数の平均と分布を見て、総合的に判断する必要があります。また、Calibrationを検討する際には、val / testの予測値の平均値とtrainの目的変数の平均値を見て一致しているかを確認し、train / val / testの予測値の分布を見ることが重要です。\n",
      "参照url1: https://yukoishizaki.hatenablog.com/entry/2020/05/24/145155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikegamikenshin/Documents/study/chatgpt-practice/.venv/lib/python3.9/site-packages/llama_index/data_structs/node_v2.py:181: UserWarning: .extra_info is deprecated, use .node.extra_info instead\n",
      "  warnings.warn(\".extra_info is deprecated, use .node.extra_info instead\")\n"
     ]
    }
   ],
   "source": [
    "search_query = \"calibrationってどんな技術だっけ？\"\n",
    "\n",
    "response = index.query(\n",
    "    search_query,\n",
    "    similarity_top_k=3,\n",
    "    text_qa_template=CUSTOM_TEXT_QA_PROMPT,\n",
    "    refine_template=CUSTOM_REFINE_PROMPT\n",
    ")\n",
    "\n",
    "print(f\"response: {response.response}\")\n",
    "\n",
    "reffer_urls = set([source_node.extra_info[\"url\"] for source_node in response.source_nodes])\n",
    "for i, url in enumerate(reffer_urls):\n",
    "    print(f\"参照url{i+1}: {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc5241d",
   "metadata": {},
   "source": [
    "# Documentの追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27ea08f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/chatgpt_search_collection \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CollectionInfo(status=<CollectionStatus.GREEN: 'green'>, optimizer_status=<OptimizersStatusOneOf.OK: 'ok'>, vectors_count=10, indexed_vectors_count=0, points_count=10, segments_count=4, config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=1536, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=True), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None), payload_schema={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_collection(collection_name=COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75090193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/chatgpt_search_collection/points/scroll \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: PUT http://localhost:6333/collections/chatgpt_search_collection/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.token_counter.token_counter:> [insert] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [insert] Total embedding token usage: 13970 tokens\n"
     ]
    }
   ],
   "source": [
    "results, _ = client.scroll(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    scroll_filter=qdrant_client.http.models.Filter(\n",
    "        must=[\n",
    "            qdrant_client.http.models.FieldCondition(\n",
    "                key=\"extra_info.url\",\n",
    "                match=qdrant_client.http.models.MatchValue(value=ADDITIONAL_URL)\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# 既に登録されているURLの場合はskip\n",
    "if not results:\n",
    "    \n",
    "    additional_urls = [ADDITIONAL_URL]\n",
    "    additional_documents = SimpleWebPageReader(html_to_text=True).load_data(additional_urls)\n",
    "\n",
    "    # extra_infoにurlを追加\n",
    "    for additional_document, url in zip(additional_documents, additional_urls):\n",
    "        additional_document.extra_info = {\"url\": url}\n",
    "    \n",
    "    # insert\n",
    "    for additional_document in additional_documents:\n",
    "        index.insert(additional_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "530938e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/chatgpt_search_collection \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CollectionInfo(status=<CollectionStatus.GREEN: 'green'>, optimizer_status=<OptimizersStatusOneOf.OK: 'ok'>, vectors_count=14, indexed_vectors_count=0, points_count=14, segments_count=4, config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=1536, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=True), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None), payload_schema={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_collection(collection_name=COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8176638f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/chatgpt_search_collection/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 15090 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 10 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: Qdrantの特徴は、オープンソースのRust製ベクトル検索エンジンであり、Python SDK、REST API、gRPCを介してクライアントが接続できること、ベクトル検索においてコサイン類似度を使用していること、大規模なデータセットにも対応できることなどです。Qdrantではコレクションとポイントの概念があり、コレクションはRDBのテーブルに相当し、ポイントはRDBのレコードに相当します。Python SDKを使用してコレクションの作成、ドキュメントの登録、類似ドキュメントの検索が可能であり、絞り込み検索もサポートしています。また、Qdrantを使用したデモサイトも存在し、キーワード検索もサポートしています。ただし、Qdrant自体にはベクトル化の機能は無いため、ドキュメントをベクトル化する必要があります。Qdrantは、Facebook FaissやPynndescentなどのライブラリと比較しても高速であり、大規模なデータセットにも対応できます。\n",
      "参照url1: https://zenn.dev/tfutada/articles/acf8adbb2ba5be\n"
     ]
    }
   ],
   "source": [
    "search_query = \"Qdrantの特徴は?\"\n",
    "\n",
    "response = index.query(\n",
    "    search_query,\n",
    "    similarity_top_k=3,\n",
    "    text_qa_template=CUSTOM_TEXT_QA_PROMPT,\n",
    "    refine_template=CUSTOM_REFINE_PROMPT\n",
    ")\n",
    "\n",
    "print(f\"response: {response.response}\")\n",
    "\n",
    "reffer_urls = set([source_node.extra_info[\"url\"] for source_node in response.source_nodes])\n",
    "for i, url in enumerate(reffer_urls):\n",
    "    print(f\"参照url{i+1}: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2af71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3466fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexをローカルに保存\n",
    "index.save_to_disk(\"../data/qdrant_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "595663eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index delete用\n",
    "# client.delete_collection(collection_name=COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a1fcdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
